{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plyfile import PlyData, PlyElement \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "import os, glob, re, shutil\n",
    "import PIL.ExifTags as ExifTags\n",
    "import PIL.Image as Image\n",
    "from PIL import ImageOps\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from typing import Union\n",
    "# import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# same with .npy file just no \"data\" key\n",
    "file_path = '/cs/student/projects4/ml/2023/asrivast/datasets/bicycle/poses_bounds.npy'\n",
    "# load the .npy data\n",
    "data = np.load(file_path)\n",
    "print(data.shape)\n",
    "\n",
    "for i in range(0, 10):\n",
    "    print(data[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the .ply file from COLMAP and converting it to .npz\n",
    "\n",
    "format of numpy array to be stored in .npz file\n",
    "* (N, 7) where N is total number of points\n",
    "* 0-2 x,y,z\n",
    "* 3-5 R,G,B\n",
    "* 7 all ones\n",
    "\n",
    "\n",
    "Additionally we may remove points outside some bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parent_dir= \"/cs/student/projects4/ml/2023/asrivast/datasets/portsmouth_video/frames/sparse_000001/0/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: float32, y: float32, z: float32, r: uint8, g: uint8, b: uint8, seven: float32\n",
      "x: float32, y: float32, z: float32, r: float32, g: float32, b: float32, seven: float32\n",
      "points shape: (5340, 7)\n",
      "Saved /cs/student/projects4/ml/2023/asrivast/datasets/portsmouth_video/frames/sparse_000001/0//init_pt_cld.npz\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ply_file= f\"{parent_dir}/points3D.ply\"\n",
    "with open(ply_file, 'rb') as f:\n",
    "    ply_data: PlyData = PlyData.read(f)\n",
    "    x = ply_data['vertex']['x']\n",
    "    y = ply_data['vertex']['y']\n",
    "    \n",
    "    # make a plot of x and y values using plotly\n",
    "    z = ply_data['vertex']['z']\n",
    "\n",
    "\n",
    "\n",
    "    r = ply_data['vertex']['red']\n",
    "    g = ply_data['vertex']['green']\n",
    "    b = ply_data['vertex']['blue']\n",
    "    seven= np.ones(x.shape[0], dtype=np.float32)\n",
    "\n",
    "    # print data types of each\n",
    "    print(f\"x: {x.dtype}, y: {y.dtype}, z: {z.dtype}, r: {r.dtype}, g: {g.dtype}, b: {b.dtype}, seven: {seven.dtype}\")\n",
    "\n",
    "    # need to change the dtype of R G B to float32 as well\n",
    "    r = r.astype(np.float32)/255\n",
    "    g = g.astype(np.float32)/255\n",
    "    b = b.astype(np.float32)/255\n",
    "\n",
    "\n",
    "    print(f\"x: {x.dtype}, y: {y.dtype}, z: {z.dtype}, r: {r.dtype}, g: {g.dtype}, b: {b.dtype}, seven: {seven.dtype}\")\n",
    "\n",
    "    # filter points based on position\n",
    "    index= (x<.4) & (x>-.2) & (z<.2) & (z>-.2) \n",
    "    x= x[index]\n",
    "    y= y[index]\n",
    "    z= z[index]\n",
    "    r= r[index]\n",
    "    g= g[index]\n",
    "    b= b[index]\n",
    "    seven= seven[index]\n",
    "\n",
    "    # stack them together\n",
    "    points = np.vstack((x, y, z, r, g, b, seven)).T\n",
    "    print(f\"points shape: {points.shape}\")\n",
    "    \n",
    "    # now save it as a .npz file with a key \"data\"\n",
    "    npz_file= f\"{parent_dir}/init_pt_cld.npz\"\n",
    "    npz= {}\n",
    "    np.savez_compressed(npz_file, data=points)\n",
    "    print(f\"Saved {npz_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading points3D.bin and convert it to .npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils_data_making\n",
    "import utils_colmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max RGB: 255.0\n",
      "Max RGB: 1.0\n",
      "Point cloud saved\n"
     ]
    }
   ],
   "source": [
    "bin_path = os.path.join(f\"{parent_dir}/points3D.bin\")\n",
    "xyzs, rgbs, _ = utils_colmap.read_points3D_binary(bin_path)\n",
    "seg = np.ones_like(xyzs[:, 0])[:, None]   # Always dynamic for now, segmentation always 1\n",
    "# print current max rgb\n",
    "print(f\"Max RGB: {rgbs.max()}\")\n",
    "rgbs = rgbs / 255.0\n",
    "print(f\"Max RGB: {rgbs.max()}\")\n",
    "pt_cld = dict()\n",
    "pt_cld = np.concatenate((xyzs, rgbs, seg), axis=1).tolist()\n",
    "# if not os.path.exists(os.path.join(\".\")):\n",
    "#     os.makedirs(os.path.join(args.output_path, args.dataset_name))\n",
    "np.savez(os.path.join(f'{parent_dir}/init_pt_cld_other.npz'), data=pt_cld)\n",
    "print('Point cloud saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the .npz file and converting it to .ply file\n",
    "\n",
    "only for visualisation before we feed it to the Dynamic 3DGS pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5340, 7)\n",
      "float32 float32 float32\n",
      "RGB_SCALE: 255\n",
      "PLY file saved to /cs/student/projects4/ml/2023/asrivast/datasets/portsmouth_video/frames/sparse_000001/0//init_pt_cld.ply\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming 'points' is your numpy array of shape (N, 7)\n",
    "# Load or define your numpy array here if needed\n",
    "npz_file = f'{parent_dir}/init_pt_cld.npz'\n",
    "\n",
    "# Load the .npz file\n",
    "data = np.load(npz_file)\n",
    "print(data['data'].shape,)\n",
    "print(data['data'][:,0].dtype, data['data'][:,3].dtype, data['data'][:,6].dtype)\n",
    "points = data['data']\n",
    "\n",
    "# Extract the first 6 columns for x, y, z, R, G, B\n",
    "vertices_data = points[:, :6]\n",
    "\n",
    "# # Convert to a list of tuples, each tuple representing a vertex\n",
    "vertices_list = [tuple(vertex) for vertex in vertices_data]\n",
    "# scale and convert to uint all RGB values\n",
    "RGB_SCALE = 1 if np.max(vertices_data[:,3:6]) > 1 else 255\n",
    "print(f\"RGB_SCALE: {RGB_SCALE}\")\n",
    "vertices_list = [(x, y, z, int(r* RGB_SCALE), int(g* RGB_SCALE), int(b*RGB_SCALE)) for x, y, z, r, g, b in vertices_list]\n",
    "\n",
    "# # Define the vertex element\n",
    "vertex_element = PlyElement.describe(np.array(vertices_list, dtype=[('x', 'f4'), ('y', 'f4'), ('z', 'f4'), ('red', 'u1'), ('green', 'u1'), ('blue', 'u1')]), 'vertex')\n",
    "\n",
    "# # Create the PlyData object\n",
    "ply_data = PlyData([vertex_element])\n",
    "\n",
    "# # Save the .ply file\n",
    "ply_file_path = f\"{parent_dir}/init_pt_cld.ply\"\n",
    "ply_data.write(ply_file_path)\n",
    "\n",
    "print(f\"PLY file saved to {ply_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the .bin files from COLMAP and converting it to train_meta.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First we see what kind of file is train_meta.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 5]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a= [1,2,3,4,5,6,7]\n",
    "# get third and fifth element\n",
    "b= [a[2], a[4]]\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir= \"/cs/student/projects4/ml/2023/asrivast/datasets/dynamic_3DGS/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded /cs/student/projects4/ml/2023/asrivast/datasets/dynamic_3DGS/data//portsmouth/train_meta.json\n",
      "w: 1220\n",
      "h: 994\n",
      "k: (199, 28, 3, 3)\n",
      "w2c: (199, 28, 4, 4)\n",
      "fn: (199, 28)\n",
      "cam_id: (199, 28)\n"
     ]
    }
   ],
   "source": [
    "meta_json= f\"{parent_dir}/portsmouth/train_meta.json\"\n",
    "\n",
    "k_unique= []\n",
    "w2c_unique= []\n",
    "cam_id_unique= []\n",
    "\n",
    "unique_cam_ids= []\n",
    "\n",
    "with open(meta_json, 'r') as f:\n",
    "    meta_dict= json.load(f)\n",
    "    print(f\"Loaded {meta_json}\")\n",
    "    for key in meta_dict.keys():\n",
    "        value= np.array(meta_dict[key])\n",
    "        if value.shape == ():\n",
    "            print(f\"{key}: {value}\")\n",
    "        else:\n",
    "            print(f\"{key}: {value.shape}\")\n",
    "\n",
    "\n",
    "        if key == \"k\":\n",
    "            total_frames= np.array(meta_dict[key]).shape[0]\n",
    "            total_cams= np.array(meta_dict[key]).shape[1]\n",
    "            for frame in range(total_frames):\n",
    "                for cam in range(total_cams):\n",
    "                    k_new= meta_dict[key][frame][cam]\n",
    "                    \n",
    "                    for old_k in k_unique:\n",
    "                        if np.allclose(k_new, old_k):\n",
    "                            break\n",
    "                    else:\n",
    "                        k_unique.append(k_new)\n",
    "\n",
    "        if key == \"w2c\":\n",
    "            total_frames= np.array(meta_dict[key]).shape[0]\n",
    "            total_cams= np.array(meta_dict[key]).shape[1]\n",
    "            for frame in range(total_frames):\n",
    "                for cam in range(total_cams):\n",
    "                    w2c_new= meta_dict[key][frame][cam]\n",
    "                    \n",
    "                    for old_w2c in w2c_unique:\n",
    "                        if np.allclose(w2c_new, old_w2c):\n",
    "                            break\n",
    "                    else:\n",
    "                        w2c_unique.append(w2c_new)\n",
    "\n",
    "        if key == \"cam_id\":\n",
    "            total_frames= np.array(meta_dict[key]).shape[0]\n",
    "            total_cams= np.array(meta_dict[key]).shape[1]\n",
    "            for frame in range(total_frames):\n",
    "                for cam in range(total_cams):\n",
    "                    cam_id_new= meta_dict[key][frame][cam]\n",
    "                    \n",
    "                    for old_cam_id in cam_id_unique:\n",
    "                        if cam_id_new == old_cam_id:\n",
    "                            break\n",
    "                    else:\n",
    "                        cam_id_unique.append(cam_id_new)\n",
    "\n",
    "                    \n",
    "\n",
    "    # print(\"#####################\")\n",
    "    # k_np= np.array(meta_dict['k'])\n",
    "    # k_np= k_np[:,(0, -1), :,:]\n",
    "    # print(k_np.shape)\n",
    "\n",
    "    # w2c_np= np.array(meta_dict['w2c'])\n",
    "    # w2c_np= w2c_np[:,(0, -1), :,:]\n",
    "    # print(w2c_np.shape)\n",
    "\n",
    "    # fn_np= np.array(meta_dict['fn'])\n",
    "    # fn_np= fn_np[:,(0, -1)]\n",
    "    # print(fn_np.shape)\n",
    "\n",
    "    # cam_id_np= np.array(meta_dict['cam_id'])\n",
    "    # cam_id_np= cam_id_np[:,(0, -1)]\n",
    "    # print(cam_id_np.shape)\n",
    "\n",
    "    # new_meta_dict= meta_dict.copy()\n",
    "    # new_meta_dict['k']= k_np.tolist()\n",
    "    # new_meta_dict['w2c']= w2c_np.tolist()\n",
    "    # new_meta_dict['fn']= fn_np.tolist()\n",
    "    # new_meta_dict['cam_id']= cam_id_np.tolist()\n",
    "    # with open(\"test_meta.json\", 'w') as f:\n",
    "    #     json.dump(new_meta_dict, f, indent=4)\n",
    "    #     print(f\"Saved test_meta.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "28\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "print(len(k_unique))\n",
    "print(len(w2c_unique))\n",
    "print(len(cam_id_unique))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# from .bin file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: Camera(id=1, model='PINHOLE', width=1220, height=994, params=array([1928.96714337, 1920.45748488,  610.        ,  497.        ]))}\n",
      "<class 'dict'>\n",
      "<class 'read_write_model.Camera'>\n",
      "Camera(id=1, model='PINHOLE', width=1220, height=994, params=array([1928.96714337, 1920.45748488,  610.        ,  497.        ]))\n"
     ]
    }
   ],
   "source": [
    "import read_write_model\n",
    "\n",
    "cams= read_write_model.read_cameras_binary(\"/cs/student/projects4/ml/2023/asrivast/datasets/portsmouth_video/frames/sparse_000001/0/cameras.bin\")\n",
    "print(cams)\n",
    "print(type(cams))\n",
    "print(type(cams[1]))\n",
    "print(cams[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLMAP index 1 cam-005_000001.jpg CAM num 5\n",
      "COLMAP index 2 cam-002_000001.jpg CAM num 2\n",
      "COLMAP index 3 cam-006_000001.jpg CAM num 6\n",
      "COLMAP index 4 cam-007_000001.jpg CAM num 7\n",
      "COLMAP index 5 cam-001_000001.jpg CAM num 1\n",
      "COLMAP index 6 cam-003_000001.jpg CAM num 3\n",
      "COLMAP index 7 cam-008_000001.jpg CAM num 8\n",
      "COLMAP index 8 cam-011_000001.jpg CAM num 11\n",
      "COLMAP index 9 cam-010_000001.jpg CAM num 10\n",
      "COLMAP index 10 cam-009_000001.jpg CAM num 9\n",
      "COLMAP index 11 cam-004_000001.jpg CAM num 4\n",
      "COLMAP index 12 cam-012_000001.jpg CAM num 12\n",
      "COLMAP index 13 cam-013_000001.jpg CAM num 13\n",
      "COLMAP index 14 cam-014_000001.jpg CAM num 14\n",
      "COLMAP index 15 cam-015_000001.jpg CAM num 15\n",
      "COLMAP index 16 cam-021_000001.jpg CAM num 21\n",
      "COLMAP index 17 cam-022_000001.jpg CAM num 22\n",
      "COLMAP index 18 cam-016_000001.jpg CAM num 16\n",
      "COLMAP index 19 cam-017_000001.jpg CAM num 17\n",
      "COLMAP index 20 cam-018_000001.jpg CAM num 18\n",
      "COLMAP index 21 cam-019_000001.jpg CAM num 19\n",
      "COLMAP index 22 cam-020_000001.jpg CAM num 20\n",
      "COLMAP index 23 cam-024_000001.jpg CAM num 24\n",
      "COLMAP index 24 cam-023_000001.jpg CAM num 23\n",
      "COLMAP index 25 cam-025_000001.jpg CAM num 25\n",
      "COLMAP index 26 cam-026_000001.jpg CAM num 26\n",
      "COLMAP index 27 cam-027_000001.jpg CAM num 27\n",
      "COLMAP index 28 cam-029_000001.jpg CAM num 29\n",
      "COLMAP index 29 cam-028_000001.jpg CAM num 28\n",
      "COLMAP index 30 cam-030_000001.jpg CAM num 30\n",
      "COLMAP index 31 cam-031_000001.jpg CAM num 31\n",
      "COLMAP index 32 cam-032_000001.jpg CAM num 32\n"
     ]
    }
   ],
   "source": [
    "images= read_write_model.read_images_binary(\"/cs/student/projects4/ml/2023/asrivast/datasets/portsmouth_video/frames/sparse_000001/0/images.bin\")\n",
    "# total number of keys= total number of images\n",
    "cam_id_map = {} # cameran_num : COLMAP index\n",
    "for COLMAP_index in images.keys():\n",
    "    camera_num= int(re.split(\"[-_]\", images[COLMAP_index].name)[1])\n",
    "    cam_id_map[camera_num]= COLMAP_index\n",
    "    print(\"COLMAP index\", COLMAP_index, images[COLMAP_index].name, \"CAM num\", camera_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cams= [i for i in range(1, 33)] # all cameras\n",
    "train_cams= [cam_id_map[cam] for cam in train_cams]\n",
    "\n",
    "\n",
    "test_cams= [2,15,25,30] \n",
    "test_cams= [cam_id_map[cam] for cam in test_cams]\n",
    "\n",
    "# remove test cams from train cams\n",
    "train_cams= [cam for cam in train_cams if cam not in test_cams]\n",
    "\n",
    "\n",
    "k_np= np.zeros((len(train_cams),3,3))\n",
    "w2c_np= np.zeros((len(train_cams),4,4))\n",
    "fn = []\n",
    "cam_ids_np= np.zeros(len(train_cams), dtype=np.uint)\n",
    "\n",
    "\n",
    "for i, image_id in enumerate(train_cams):\n",
    "    \n",
    "    img_name= images[image_id].name\n",
    "    cam_obj= cams[images[image_id].camera_id]\n",
    "\n",
    "    q_vec= images[image_id].qvec\n",
    "    t_vec= images[image_id].tvec\n",
    "\n",
    "    w= cam_obj.width\n",
    "    h= cam_obj.height\n",
    "\n",
    "    fx= cam_obj.params[0]\n",
    "    fy= cam_obj.params[1]\n",
    "    cx= cam_obj.params[2]\n",
    "    cy= cam_obj.params[3]\n",
    "\n",
    "\n",
    "    k= np.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n",
    "    w2c= np.eye(4)\n",
    "    w2c[:3,:3]= read_write_model.qvec2rotmat(q_vec)\n",
    "    w2c[:3,3]= t_vec\n",
    "\n",
    "    k_np[i]= k\n",
    "    w2c_np[i]= np.linalg.pinv(w2c)\n",
    "    \n",
    "\n",
    "    fn.append(img_name)\n",
    "    cam_ids_np[i]= image_id\n",
    "\n",
    "# for image_obj in images:\n",
    "#     print(type(images[image_obj]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k  (28, 3, 3)\n",
      "w2c  (28, 4, 4)\n",
      "fn  28\n",
      "cam_id (28,)\n"
     ]
    }
   ],
   "source": [
    "# print shapes of all arrays to which we added in previous steps\n",
    "print(\"k \", k_np.shape)\n",
    "print(\"w2c \", w2c_np.shape)\n",
    "print(\"fn \", len(fn))\n",
    "print(\"cam_id\", cam_ids_np.shape)\n",
    "\n",
    "# print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cam-001_000001.jpg',\n",
       " 'cam-003_000001.jpg',\n",
       " 'cam-004_000001.jpg',\n",
       " 'cam-005_000001.jpg',\n",
       " 'cam-006_000001.jpg',\n",
       " 'cam-007_000001.jpg',\n",
       " 'cam-008_000001.jpg',\n",
       " 'cam-009_000001.jpg',\n",
       " 'cam-010_000001.jpg',\n",
       " 'cam-011_000001.jpg',\n",
       " 'cam-012_000001.jpg',\n",
       " 'cam-013_000001.jpg',\n",
       " 'cam-014_000001.jpg',\n",
       " 'cam-016_000001.jpg',\n",
       " 'cam-017_000001.jpg',\n",
       " 'cam-018_000001.jpg',\n",
       " 'cam-019_000001.jpg',\n",
       " 'cam-020_000001.jpg',\n",
       " 'cam-021_000001.jpg',\n",
       " 'cam-022_000001.jpg',\n",
       " 'cam-023_000001.jpg',\n",
       " 'cam-024_000001.jpg',\n",
       " 'cam-026_000001.jpg',\n",
       " 'cam-027_000001.jpg',\n",
       " 'cam-028_000001.jpg',\n",
       " 'cam-029_000001.jpg',\n",
       " 'cam-031_000001.jpg',\n",
       " 'cam-032_000001.jpg']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now add a dimension in beggining in each of them and repeat them total_frames times\n",
    "total_frames= 199\n",
    "k_np_full = np.repeat(k_np[np.newaxis, ...], total_frames, axis=0)\n",
    "w2c_np_full = np.repeat(w2c_np[np.newaxis, ...], total_frames, axis=0)\n",
    "\n",
    "\n",
    "fn_full= []\n",
    "for i in range(1, total_frames+1):\n",
    "    frame_num= str(i).zfill(6)\n",
    "    fn_new= fn.copy()\n",
    "    for i,_ in enumerate(fn_new):\n",
    "        cam_num= int(re.split(\"[-_]\", _)[1])\n",
    "        fn_new[i]= fn_new[i].replace(\"000001\", frame_num)\n",
    "        fn_new[i]= f\"{cam_num}/{fn_new[i][8:-4]}.JPG\"\n",
    "\n",
    "        \n",
    "    fn_full.append(fn_new)\n",
    "\n",
    "cam_ids_np_full= np.repeat(cam_ids_np[np.newaxis, ...], total_frames, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k  (199, 28, 3, 3)\n",
      "w2c  (199, 28, 4, 4)\n",
      "fn  (199, 28)\n",
      "cam_id (199, 28)\n"
     ]
    }
   ],
   "source": [
    "# print shapes along with names agains\n",
    "print(\"k \", k_np_full.shape)\n",
    "print(\"w2c \", w2c_np_full.shape)\n",
    "print(\"fn \", np.array(fn_full).shape)\n",
    "print(\"cam_id\", cam_ids_np_full.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1/000199.JPG',\n",
       " '3/000199.JPG',\n",
       " '4/000199.JPG',\n",
       " '5/000199.JPG',\n",
       " '6/000199.JPG',\n",
       " '7/000199.JPG',\n",
       " '8/000199.JPG',\n",
       " '9/000199.JPG',\n",
       " '10/000199.JPG',\n",
       " '11/000199.JPG',\n",
       " '12/000199.JPG',\n",
       " '13/000199.JPG',\n",
       " '14/000199.JPG',\n",
       " '16/000199.JPG',\n",
       " '17/000199.JPG',\n",
       " '18/000199.JPG',\n",
       " '19/000199.JPG',\n",
       " '20/000199.JPG',\n",
       " '21/000199.JPG',\n",
       " '22/000199.JPG',\n",
       " '23/000199.JPG',\n",
       " '24/000199.JPG',\n",
       " '26/000199.JPG',\n",
       " '27/000199.JPG',\n",
       " '28/000199.JPG',\n",
       " '29/000199.JPG',\n",
       " '31/000199.JPG',\n",
       " '32/000199.JPG']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn_full[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved /cs/student/projects4/ml/2023/asrivast/datasets/dynamic_3DGS/data/portsmouth/train_meta.json\n"
     ]
    }
   ],
   "source": [
    "meta_dict= {\"w\": 1220,\n",
    "            \"h\": 994,\n",
    "            \"k\": k_np_full.tolist(),\n",
    "            \"w2c\": w2c_np_full.tolist(),\n",
    "            \"fn\": fn_full,\n",
    "            # \"cam_id\": cam_ids_np_full.tolist()\n",
    "            }\n",
    "\n",
    "json_path= \"/cs/student/projects4/ml/2023/asrivast/datasets/dynamic_3DGS/data/portsmouth/train_meta.json\"\n",
    "with open(json_path, 'w') as meta_json:\n",
    "    json.dump(meta_dict, meta_json, indent=4)\n",
    "    print(f\"Saved {json_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the output .npz file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "means3D: (11, 355146, 3)\n",
      "rgb_colors: (11, 355146, 3)\n",
      "seg_colors: (355146, 3)\n",
      "unnorm_rotations: (11, 355146, 4)\n",
      "logit_opacities: (355146, 1)\n",
      "log_scales: (355146, 3)\n",
      "cam_m: (50, 3)\n",
      "[[ 0.04052375  0.04089984  0.03511785]\n",
      " [-0.10412157 -0.11086568 -0.11600678]\n",
      " [ 0.03189565  0.04502699  0.03034953]\n",
      " [-0.06717889 -0.07117973 -0.08319283]\n",
      " [-0.00327357  0.01511976  0.0076265 ]\n",
      " [ 0.09751539  0.09298394  0.10647158]\n",
      " [ 0.05988395  0.03975919  0.05563907]\n",
      " [ 0.00337028  0.01964025  0.00806313]\n",
      " [-0.00923424  0.01268488  0.0058958 ]\n",
      " [-0.11130295 -0.11080908 -0.11390278]\n",
      " [-0.01869849 -0.02034263 -0.01551975]\n",
      " [-0.05780772 -0.06925236 -0.06072897]\n",
      " [-0.01703494 -0.00727891 -0.01703449]\n",
      " [-0.0618599  -0.06228618 -0.06967499]\n",
      " [ 0.02166728  0.01342456  0.01806911]\n",
      " [-0.02762344 -0.01596763 -0.02078595]\n",
      " [ 0.06977711  0.07378475  0.07342494]\n",
      " [ 0.00482329  0.03206026  0.01437046]\n",
      " [-0.06484304 -0.0602063  -0.05086702]\n",
      " [-0.01094176  0.00574239 -0.00309625]\n",
      " [-0.01958307 -0.01359787 -0.03105757]\n",
      " [ 0.03879856  0.05522519  0.04081517]\n",
      " [ 0.00446327  0.02420064  0.01038058]\n",
      " [-0.05143015 -0.03266343 -0.04018358]\n",
      " [-0.00124511 -0.00820479 -0.01251591]\n",
      " [ 0.06880892  0.07516009  0.06352902]\n",
      " [ 0.00677203  0.02519674  0.0136299 ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          0.        ]]\n",
      "cam_c: (50, 3)\n",
      "[[ 1.3023651e-02  1.2216690e-02  9.4753299e-03]\n",
      " [-4.7699619e-02 -4.6484873e-02 -3.3240341e-02]\n",
      " [ 4.6522478e-03  1.8346211e-02  9.5177209e-03]\n",
      " [-2.2715945e-02 -2.1775888e-02 -1.1982528e-02]\n",
      " [ 1.1873618e-02  2.5734315e-02  1.5955938e-02]\n",
      " [ 4.7432352e-02  3.7836485e-02  3.3366151e-02]\n",
      " [ 4.7400787e-02  3.0307462e-02  3.1240460e-02]\n",
      " [-2.3362923e-03  9.7170668e-03  1.5298919e-03]\n",
      " [ 1.3477121e-02  2.3698987e-02  1.8676233e-02]\n",
      " [-2.2566020e-02 -1.3246842e-02 -1.1143688e-02]\n",
      " [-4.9651046e-03  5.3824391e-03  1.3924115e-03]\n",
      " [-3.5114229e-02 -3.2718338e-02 -2.6434917e-02]\n",
      " [ 1.3362716e-02  2.3168443e-02  1.2997352e-02]\n",
      " [-1.6140668e-02 -1.6626365e-02 -7.8642983e-03]\n",
      " [ 1.8322039e-03 -2.1871159e-04  3.6166096e-03]\n",
      " [-2.0286574e-03  5.2784616e-03  3.5494531e-03]\n",
      " [ 3.2650799e-02  3.1488955e-02  2.7200105e-02]\n",
      " [ 1.1682409e-02  2.1371709e-02  1.3084695e-02]\n",
      " [-1.0073976e-02 -1.5231232e-03 -1.4275152e-03]\n",
      " [ 9.3688890e-03  1.7025277e-02  8.2872119e-03]\n",
      " [ 1.1089614e-02  1.9621681e-02  6.8977131e-03]\n",
      " [ 3.3704133e-03  1.5670732e-02  1.1884579e-02]\n",
      " [ 2.0672688e-02  2.9772418e-02  2.1322921e-02]\n",
      " [ 3.0693650e-02  4.5233939e-02  3.1079266e-02]\n",
      " [-1.0820111e-02 -9.4615592e-04 -5.3677438e-03]\n",
      " [ 5.5449832e-02  5.0593715e-02  3.8619403e-02]\n",
      " [ 4.4490727e-05  1.2990945e-02  7.0567350e-03]\n",
      " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      " [ 0.0000000e+00  0.0000000e+00  0.0000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "npz_file= \"/cs/student/projects4/ml/2023/asrivast/datasets/dynamic_3DGS/output/exp3/boxes/params.npz\"\n",
    "with np.load(npz_file) as data:\n",
    "    for file in data.files:\n",
    "        print(f\"{file}: {data[file].shape}\")\n",
    "\n",
    "        if file == \"cam_m\" or file == \"cam_c\":\n",
    "            print(data[file])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move first frame to a new folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os, glob, re, shutil\n",
    "import PIL.ExifTags as ExifTags\n",
    "import PIL.Image as Image\n",
    "from PIL import ImageOps\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from typing import Union\n",
    "import piexif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:00<00:00, 527.43it/s]\n"
     ]
    }
   ],
   "source": [
    "all_jpgs= glob.glob(\"/cs/student/projects4/ml/2023/asrivast/datasets/dynamic_3DGS/data/basketball/ims/*/000000.jpg\")\n",
    "print(len(all_jpgs))\n",
    "\n",
    "new_folder= \"/cs/student/projects4/ml/2023/asrivast/datasets/dynamic_3DGS/data/basketball/frame_000000\"\n",
    "os.makedirs(new_folder, exist_ok=True)\n",
    "for jpg in tqdm(all_jpgs):\n",
    "    cam_num= os.path.basename(os.path.dirname(jpg))\n",
    "    frame0_file= os.path.join(new_folder, f\"cam-{cam_num}_000000.jpg\")\n",
    "    shutil.copy2(jpg, frame0_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gaussian_splatting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
